{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datadrive/anaconda3/envs/habitat/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# testing habitat lab setup\n",
    "import sys\n",
    "import math\n",
    "import io\n",
    "from typing import Dict, Any\n",
    "import habitat\n",
    "import numpy as np\n",
    "import quaternion\n",
    "from scipy.spatial.transform import Rotation\n",
    "from habitat.core.utils import try_cv2_import\n",
    "from habitat.utils.visualizations import maps\n",
    "from torchlightning_utils import cli\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "cv2 = try_cv2_import()\n",
    "\n",
    "# todo: implement metrics\n",
    "# todo: pose and maps transform\n",
    "\n",
    "\n",
    "def draw_top_down_map(info, output_size):\n",
    "    return maps.colorize_draw_agent_and_fit_to_height(info[\"top_down_map\"], output_size)\n",
    "\n",
    "\n",
    "def map_centered_by_agent(info) -> np.ndarray:\n",
    "    \"\"\"Center the map wrt to agent's pose.\n",
    "\n",
    "    Args:\n",
    "        info (dict): _description_\n",
    "    \"\"\"\n",
    "    env_map = info[\"top_down_map\"][\"map\"]\n",
    "    agent_map_pose = np.array(\n",
    "        [\n",
    "            info[\"top_down_map\"][\"agent_map_coord\"][0],\n",
    "            info[\"top_down_map\"][\"agent_map_coord\"][1],\n",
    "            info[\"top_down_map\"][\"agent_angle\"],\n",
    "        ]\n",
    "    )\n",
    "    cx = agent_map_pose[0]\n",
    "    cy = agent_map_pose[1]\n",
    "    map_size = min(info[\"top_down_map\"][\"map\"].shape)\n",
    "    rect = (\n",
    "        (cx, cy),\n",
    "        (map_size, map_size),\n",
    "        90 - math.degrees(agent_map_pose[2]),\n",
    "    )\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    # get width and height of the detected rectangle\n",
    "    width = int(rect[1][0])\n",
    "    height = int(rect[1][1])\n",
    "    src_pts = box.astype(\"float32\")\n",
    "    # coordinate of the points in box points after the rectangle has been\n",
    "    # straightened\n",
    "    dst_pts = np.array(\n",
    "        [[0, height - 1], [0, 0], [width - 1, 0], [width - 1, height - 1]],\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "    # the perspective transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    # directly warp the rotated rectangle to get the straightened rectangle\n",
    "    warped_map = cv2.warpPerspective(env_map, M, (width, height))\n",
    "    return warped_map\n",
    "\n",
    "\n",
    "def get_2dpose(env: habitat.Env):\n",
    "    \"\"\"Return agent's pose in both simulation env and also wrt map.\n",
    "\n",
    "    Args:\n",
    "        env (habitat.Env): current environment\n",
    "\n",
    "    Returns:\n",
    "        dict:\n",
    "            pose (np.ndarray): agent's pose wrt simulation env, 4d with 1-3d representing position, last entry represents yaw\n",
    "    \"\"\"\n",
    "    agent_state = env._sim.get_agent_state()\n",
    "    rotation_angles = Rotation.from_quat(\n",
    "        quaternion.as_float_array(agent_state.rotation)\n",
    "    ).as_euler(\"ZYX\", degrees=False)\n",
    "    pose = np.concatenate(\n",
    "        [\n",
    "            agent_state.position,\n",
    "            [rotation_angles[1]],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pose\n",
    "\n",
    "\n",
    "def pltimg(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Given an image (not rgb), use plt to transform it image rgb image\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): image with leading two dims should be width and height.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: rgb repr of img with size (original w, original h, 3)\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    fig.add_axes([0, 0, 1, 1])  # remove margins\n",
    "    plt.imshow(img)\n",
    "    buf = io.BytesIO()\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    pil_img = Image.open(buf).convert(\"RGB\").resize((img.shape[0], img.shape[1]))\n",
    "    buf.close()\n",
    "    np_img = np.asarray(pil_img)\n",
    "    return np_img\n",
    "\n",
    "\n",
    "def make_image(observations, info):\n",
    "    rgb_im = observations[\"rgb\"]\n",
    "    depth_im = pltimg(np.squeeze(observations[\"depth\"], axis=2))\n",
    "    semantic_im = pltimg(np.squeeze(observations[\"semantic\"], axis=2))\n",
    "    top_down_map = draw_top_down_map(info, rgb_im.shape[0])\n",
    "    output_im = np.concatenate((rgb_im, depth_im, semantic_im, top_down_map), axis=1)\n",
    "    return output_im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run episode\n",
    "config_path = \"/home/azureuser/AutonomousSystemsResearch/habitat-simulation/configs/collect.yaml\"\n",
    "with open(config_path, mode=\"r\") as f:\n",
    "    from omegaconf import OmegaConf\n",
    "    config = OmegaConf.create(f.read())\n",
    "    config = OmegaConf.to_container(config, resolve=True)\n",
    "\n",
    "offline_dataset_config, online_env_config = config[\"offline_dataset\"], config[\"online_env\"]\n",
    "\n",
    "\n",
    "env_config = habitat.get_config(config_paths=online_env_config[\"env_config_path\"])    \n",
    "\n",
    "with habitat.config.read_write(env_config):\n",
    "    env_config.habitat.dataset.split = online_env_config[\"env_split\"]\n",
    "    env_config.habitat.dataset.data_path = online_env_config[\"env_data_path\"]\n",
    "    env_config.habitat.dataset.scenes_dir = online_env_config[\"env_scene_dir\"]\n",
    "    env_config.habitat.simulator.scene_dataset = online_env_config[\n",
    "        \"env_scene_dataset_config\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 00:07:45,643 Initializing dataset PointNav-v1\n",
      "2023-02-03 00:07:45,824 initializing sim Sim-v0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# create env\n",
    "env = habitat.Env(config=env_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 01:28:12,040 initializing sim Sim-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  content_scenes: ['*']\n",
      "  data_path: /datadrive/azure_storage/pactdata/habitat-data/habitat-dataset/hm3d/pointnav/train/train.json.gz\n",
      "  scenes_dir: /datadrive/azure_storage/pactdata/habitat-data/habitat-dataset\n",
      "  split: train\n",
      "  type: PointNav-v1\n",
      "env_task: GymHabitatEnv\n",
      "env_task_gym_dependencies: []\n",
      "env_task_gym_id: \n",
      "environment:\n",
      "  iterator_options:\n",
      "    cycle: True\n",
      "    group_by_scene: True\n",
      "    max_scene_repeat_episodes: -1\n",
      "    max_scene_repeat_steps: 10000\n",
      "    num_episode_sample: -1\n",
      "    shuffle: True\n",
      "    step_repetition_range: 0.2\n",
      "  max_episode_seconds: 10000000\n",
      "  max_episode_steps: 500\n",
      "gym:\n",
      "  achieved_goal_keys: []\n",
      "  action_keys: None\n",
      "  auto_name: \n",
      "  desired_goal_keys: []\n",
      "  obs_keys: None\n",
      "pyrobot:\n",
      "  base_controller: proportional\n",
      "  base_planner: none\n",
      "  bump_sensor:\n",
      "    type: PyRobotBumpSensor\n",
      "  depth_sensor:\n",
      "    center_crop: False\n",
      "    height: 480\n",
      "    max_depth: 5.0\n",
      "    min_depth: 0.0\n",
      "    normalize_depth: True\n",
      "    type: PyRobotDepthSensor\n",
      "    width: 640\n",
      "  locobot:\n",
      "    actions: ['base_actions', 'camera_actions']\n",
      "    base_actions: ['go_to_relative', 'go_to_absolute']\n",
      "    camera_actions: ['set_pan', 'set_tilt', 'set_pan_tilt']\n",
      "  rgb_sensor:\n",
      "    center_crop: False\n",
      "    height: 480\n",
      "    type: PyRobotRGBSensor\n",
      "    width: 640\n",
      "  robot: locobot\n",
      "  robots: ['locobot']\n",
      "  sensors: ['rgb_sensor', 'depth_sensor', 'bump_sensor']\n",
      "seed: 100\n",
      "simulator:\n",
      "  ac_freq_ratio: 4\n",
      "  action_space_config: v0\n",
      "  additional_object_paths: []\n",
      "  agent_0:\n",
      "    height: 1.5\n",
      "    ik_arm_urdf: data/robots/hab_fetch/robots/fetch_onlyarm.urdf\n",
      "    is_set_start_state: False\n",
      "    joint_start_noise: 0.0\n",
      "    radius: 0.1\n",
      "    robot_type: FetchRobot\n",
      "    robot_urdf: data/robots/hab_fetch/robots/hab_fetch.urdf\n",
      "    sensors: ['rgb_sensor', 'depth_sensor', 'semantic_sensor']\n",
      "    start_position: [0, 0, 0]\n",
      "    start_rotation: [0, 0, 0, 1]\n",
      "  agents: ['agent_0']\n",
      "  arm_depth_sensor:\n",
      "    height: 480\n",
      "    hfov: 90\n",
      "    max_depth: 10.0\n",
      "    min_depth: 0.0\n",
      "    normalize_depth: True\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimDepthSensor\n",
      "    uuid: robot_arm_depth\n",
      "    width: 640\n",
      "  arm_rgb_sensor:\n",
      "    height: 480\n",
      "    hfov: 90\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimRGBSensor\n",
      "    uuid: robot_arm_rgb\n",
      "    width: 640\n",
      "  auto_sleep: False\n",
      "  concur_render: False\n",
      "  create_renderer: False\n",
      "  ctrl_freq: 120.0\n",
      "  debug_render: False\n",
      "  debug_render_goal: True\n",
      "  debug_render_robot: False\n",
      "  default_agent_id: 0\n",
      "  depth_sensor:\n",
      "    height: 256\n",
      "    hfov: 90\n",
      "    max_depth: 10.0\n",
      "    min_depth: 0.0\n",
      "    normalize_depth: True\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimDepthSensor\n",
      "    width: 256\n",
      "  equirect_depth_sensor:\n",
      "    height: 480\n",
      "    max_depth: 10.0\n",
      "    min_depth: 0.0\n",
      "    normalize_depth: True\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    type: HabitatSimEquirectangularDepthSensor\n",
      "    width: 640\n",
      "  equirect_rgb_sensor:\n",
      "    height: 480\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    type: HabitatSimEquirectangularRGBSensor\n",
      "    width: 640\n",
      "  equirect_semantic_sensor:\n",
      "    height: 480\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    type: HabitatSimEquirectangularSemanticSensor\n",
      "    width: 640\n",
      "  fisheye_depth_sensor:\n",
      "    alpha: 0.57\n",
      "    focal_length: [364.84, 364.86]\n",
      "    height: 480\n",
      "    max_depth: 10.0\n",
      "    min_depth: 0.0\n",
      "    normalize_depth: True\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    principal_point_offset: None\n",
      "    sensor_model_type: DOUBLE_SPHERE\n",
      "    type: HabitatSimFisheyeDepthSensor\n",
      "    width: 640\n",
      "    xi: -0.27\n",
      "  fisheye_rgb_sensor:\n",
      "    alpha: 0.57\n",
      "    focal_length: [364.84, 364.86]\n",
      "    height: 640\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    principal_point_offset: None\n",
      "    sensor_model_type: DOUBLE_SPHERE\n",
      "    type: HabitatSimFisheyeRGBSensor\n",
      "    width: 640\n",
      "    xi: -0.27\n",
      "  fisheye_semantic_sensor:\n",
      "    alpha: 0.57\n",
      "    focal_length: [364.84, 364.86]\n",
      "    height: 640\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    principal_point_offset: None\n",
      "    sensor_model_type: DOUBLE_SPHERE\n",
      "    type: HabitatSimFisheyeSemanticSensor\n",
      "    width: 640\n",
      "    xi: -0.27\n",
      "  forward_step_size: 0.25\n",
      "  grasp_impulse: 1000.0\n",
      "  habitat_sim_v0:\n",
      "    allow_sliding: True\n",
      "    enable_gfx_replay_save: False\n",
      "    enable_physics: False\n",
      "    frustum_culling: True\n",
      "    gpu_device_id: 0\n",
      "    gpu_gpu: False\n",
      "    leave_context_with_background_renderer: False\n",
      "    physics_config_file: ./data/default.physics_config.json\n",
      "  head_depth_sensor:\n",
      "    height: 480\n",
      "    hfov: 90\n",
      "    max_depth: 10.0\n",
      "    min_depth: 0.0\n",
      "    normalize_depth: True\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimDepthSensor\n",
      "    uuid: robot_head_depth\n",
      "    width: 640\n",
      "  head_rgb_sensor:\n",
      "    height: 480\n",
      "    hfov: 90\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimRGBSensor\n",
      "    uuid: robot_head_rgb\n",
      "    width: 640\n",
      "  hold_thresh: 0.09\n",
      "  kinematic_mode: False\n",
      "  lag_observations: 0\n",
      "  load_objs: False\n",
      "  needs_markers: True\n",
      "  requires_textures: True\n",
      "  rgb_sensor:\n",
      "    height: 256\n",
      "    hfov: 90\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimRGBSensor\n",
      "    width: 256\n",
      "  robot_joint_start_noise: 0.0\n",
      "  scene: /datadrive/azure_storage/pactdata/habitat-data/habitat-dataset/hm3d/train/00269-JNiWU5TZLtt/JNiWU5TZLtt.basis.glb\n",
      "  scene_dataset: /datadrive/azure_storage/pactdata/habitat-data/habitat-dataset/hm3d/hm3d_annotated_basis.scene_dataset_config.json\n",
      "  seed: 100\n",
      "  semantic_sensor:\n",
      "    height: 256\n",
      "    hfov: 90\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimSemanticSensor\n",
      "    width: 256\n",
      "  step_physics: True\n",
      "  third_depth_sensor:\n",
      "    height: 480\n",
      "    hfov: 90\n",
      "    max_depth: 10.0\n",
      "    min_depth: 0.0\n",
      "    normalize_depth: True\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimDepthSensor\n",
      "    uuid: robot_third_rgb\n",
      "    width: 640\n",
      "  third_rgb_sensor:\n",
      "    height: 480\n",
      "    hfov: 90\n",
      "    orientation: [0.0, 0.0, 0.0]\n",
      "    position: [0, 1.25, 0]\n",
      "    sensor_subtype: PINHOLE\n",
      "    type: HabitatSimRGBSensor\n",
      "    uuid: robot_third_rgb\n",
      "    width: 640\n",
      "  tilt_angle: 15\n",
      "  turn_angle: 10\n",
      "  type: Sim-v0\n",
      "  update_robot: True\n",
      "task:\n",
      "  ABS_goal_sensor:\n",
      "    dimensionality: 3\n",
      "    goal_format: CARTESIAN\n",
      "    type: AbsGoalSensor\n",
      "  ART_joint_sensor:\n",
      "    type: ArtJointSensor\n",
      "  ART_joint_sensor_NO_VEL:\n",
      "    type: ArtJointSensorNoVel\n",
      "  NAV_goal_sensor:\n",
      "    type: NavGoalSensor\n",
      "  OBJECTgoal_sensor:\n",
      "    goal_spec: TASK_CATEGORY_ID\n",
      "    goal_spec_max_val: 50\n",
      "    type: ObjectGoalSensor\n",
      "  abs_target_start_sensor:\n",
      "    dimensionality: 3\n",
      "    goal_format: CARTESIAN\n",
      "    type: AbsTargetStartSensor\n",
      "  actions:\n",
      "    answer:\n",
      "      type: AnswerAction\n",
      "    arm_action:\n",
      "      agent: None\n",
      "      arm_controller: ArmRelPosAction\n",
      "      arm_joint_dimensionality: 7\n",
      "      delta_pos_limit: 0.0125\n",
      "      disable_grip: False\n",
      "      ee_ctrl_lim: 0.015\n",
      "      grasp_thresh_dist: 0.15\n",
      "      grip_controller: None\n",
      "      render_ee_target: False\n",
      "      should_clip: False\n",
      "      type: ArmAction\n",
      "    base_velocity:\n",
      "      agent: None\n",
      "      allow_back: True\n",
      "      allow_dyn_slide: True\n",
      "      ang_speed: 10.0\n",
      "      end_on_stop: False\n",
      "      lin_speed: 10.0\n",
      "      min_abs_ang_speed: 1.0\n",
      "      min_abs_lin_speed: 1.0\n",
      "      type: BaseVelAction\n",
      "    empty:\n",
      "      type: EmptyAction\n",
      "    look_down:\n",
      "      type: LookDownAction\n",
      "    look_up:\n",
      "      type: LookUpAction\n",
      "    move_forward:\n",
      "      type: MoveForwardAction\n",
      "    oracle_nav_action:\n",
      "      agent: None\n",
      "      allow_back: True\n",
      "      allow_dyn_slide: True\n",
      "      ang_speed: 10.0\n",
      "      dist_thresh: 0.2\n",
      "      end_on_stop: False\n",
      "      forward_velocity: 1.0\n",
      "      lin_speed: 10.0\n",
      "      min_abs_ang_speed: 1.0\n",
      "      min_abs_lin_speed: 1.0\n",
      "      turn_thresh: 0.1\n",
      "      turn_velocity: 1.0\n",
      "      type: OracleNavAction\n",
      "    rearrange_stop:\n",
      "      type: RearrangeStopAction\n",
      "    stop:\n",
      "      type: StopAction\n",
      "    teleport:\n",
      "      type: TeleportAction\n",
      "    turn_left:\n",
      "      type: TurnLeftAction\n",
      "    turn_right:\n",
      "      type: TurnRightAction\n",
      "    velocity_control:\n",
      "      ang_vel_range: [-10.0, 10.0]\n",
      "      lin_vel_range: [0.0, 0.25]\n",
      "      min_abs_ang_speed: 1.0\n",
      "      min_abs_lin_speed: 0.025\n",
      "      time_step: 1.0\n",
      "      type: VelocityAction\n",
      "  answer_accuracy:\n",
      "    type: AnswerAccuracy\n",
      "  art_obj_at_desired_state:\n",
      "    success_dist_threshold: 0.05\n",
      "    type: ArtObjAtDesiredState\n",
      "    use_absolute_distance: True\n",
      "  art_obj_reward:\n",
      "    art_at_desired_state_reward: 5.0\n",
      "    art_dist_reward: 10.0\n",
      "    constraint_violate_pen: 10.0\n",
      "    dist_reward: 1.0\n",
      "    ee_dist_reward: 10.0\n",
      "    force_end_pen: 10.0\n",
      "    force_pen: 0.0\n",
      "    grasp_reward: 0.0\n",
      "    marker_dist_reward: 0.0\n",
      "    max_force_pen: 1.0\n",
      "    type: ArtObjReward\n",
      "    wrong_grasp_end: False\n",
      "    wrong_grasp_pen: 5.0\n",
      "  art_obj_state:\n",
      "    type: ArtObjState\n",
      "  art_obj_success:\n",
      "    rest_dist_threshold: 0.15\n",
      "    type: ArtObjSuccess\n",
      "  art_succ_thresh: 0.15\n",
      "  bad_called_terminate:\n",
      "    bad_term_pen: 0.0\n",
      "    decay_bad_term: False\n",
      "    type: BadCalledTerminate\n",
      "  base_angle_noise: 0.15\n",
      "  base_noise: 0.05\n",
      "  cache_robot_init: False\n",
      "  collisions:\n",
      "    type: Collisions\n",
      "  compass_sensor:\n",
      "    type: CompassSensor\n",
      "  composite_bad_called_terminate:\n",
      "    type: CompositeBadCalledTerminate\n",
      "  composite_node_idx:\n",
      "    type: CompositeNodeIdx\n",
      "  composite_reward:\n",
      "    success_reward: 10.0\n",
      "    type: CompositeReward\n",
      "  composite_stage_goals:\n",
      "    type: CompositeStageGoals\n",
      "  composite_success:\n",
      "    must_call_stop: True\n",
      "    type: CompositeSuccess\n",
      "  constraint_violation_drops_object: False\n",
      "  constraint_violation_ends_episode: True\n",
      "  correct_answer:\n",
      "    type: CorrectAnswer\n",
      "  count_obj_collisions: True\n",
      "  desired_resting_position: [0.5, 0.0, 1.0]\n",
      "  did_pick_object:\n",
      "    type: DidPickObjectMeasure\n",
      "  did_violate_hold_constraint:\n",
      "    type: DidViolateHoldConstraintMeasure\n",
      "  dist_to_goal:\n",
      "    type: DistToGoal\n",
      "  dist_to_nav_goal:\n",
      "    type: DistToNavGoalSensor\n",
      "  distance_to_goal:\n",
      "    distance_to: POINT\n",
      "    type: DistanceToGoal\n",
      "  distance_to_goal_reward:\n",
      "    type: DistanceToGoalReward\n",
      "  does_want_terminate:\n",
      "    type: DoesWantTerminate\n",
      "  easy_init: False\n",
      "  ee_dist_to_marker:\n",
      "    type: EndEffectorDistToMarker\n",
      "  ee_exclude_region: 0.0\n",
      "  ee_sample_factor: 0.2\n",
      "  end_effector_sensor:\n",
      "    type: EEPositionSensor\n",
      "  end_effector_to_object_distance:\n",
      "    type: EndEffectorToObjectDistance\n",
      "  end_effector_to_rest_distance:\n",
      "    type: EndEffectorToRestDistance\n",
      "  end_on_success: True\n",
      "  episode_info:\n",
      "    type: EpisodeInfo\n",
      "  filter_nav_to_tasks: []\n",
      "  force_regenerate: False\n",
      "  force_terminate:\n",
      "    max_accum_force: -1.0\n",
      "    max_instant_force: -1.0\n",
      "    type: ForceTerminate\n",
      "  gfx_replay_dir: data/replays\n",
      "  gfx_replay_measure:\n",
      "    type: GfxReplayMeasure\n",
      "  global_predicate_sensor:\n",
      "    type: GlobalPredicatesSensor\n",
      "  goal_sensor:\n",
      "    dimensionality: 3\n",
      "    goal_format: CARTESIAN\n",
      "    type: GoalSensor\n",
      "  goal_sensor_uuid: pointgoal_with_gps_compass\n",
      "  gps_sensor:\n",
      "    dimensionality: 2\n",
      "    type: GPSSensor\n",
      "  heading_sensor:\n",
      "    type: HeadingSensor\n",
      "  imagegoal_sensor:\n",
      "    type: ImageGoalSensor\n",
      "  instance_imagegoal_hfov_sensor:\n",
      "    type: InstanceImageGoalHFOVSensor\n",
      "  instance_imagegoal_sensor:\n",
      "    type: InstanceImageGoalSensor\n",
      "  instruction_sensor:\n",
      "    type: InstructionSensor\n",
      "  is_holding_sensor:\n",
      "    type: IsHoldingSensor\n",
      "  joint_max_impulse: -1.0\n",
      "  joint_sensor:\n",
      "    dimensionality: 7\n",
      "    type: JointSensor\n",
      "  joint_velocity_sensor:\n",
      "    dimensionality: 7\n",
      "    type: JointVelocitySensor\n",
      "  localization_sensor:\n",
      "    type: LocalizationSensor\n",
      "  marker_rel_pos_sensor:\n",
      "    type: MarkerRelPosSensor\n",
      "  measurements: ['distance_to_goal', 'success', 'spl', 'distance_to_goal_reward', 'top_down_map']\n",
      "  move_objects_reward:\n",
      "    constraint_violate_pen: 10.0\n",
      "    dist_reward: 1.0\n",
      "    force_end_pen: 10.0\n",
      "    force_pen: 0.001\n",
      "    max_force_pen: 1.0\n",
      "    pick_reward: 1.0\n",
      "    single_rearrange_reward: 1.0\n",
      "    success_dist: 0.15\n",
      "    type: MoveObjectsReward\n",
      "  must_look_at_targ: True\n",
      "  nav_to_pos_succ:\n",
      "    success_distance: 0.2\n",
      "    type: NavToPosSucc\n",
      "  nav_to_skill_sensor:\n",
      "    num_skills: 8\n",
      "    type: NavToSkillSensor\n",
      "  num_steps:\n",
      "    type: NumStepsMeasure\n",
      "  obj_at_goal:\n",
      "    succ_thresh: 0.15\n",
      "    type: ObjAtGoal\n",
      "  obj_succ_thresh: 0.3\n",
      "  object_in_hand_sample_prob: 0.167\n",
      "  object_sensor:\n",
      "    dimensionality: 3\n",
      "    goal_format: CARTESIAN\n",
      "    type: TargetCurrentSensor\n",
      "  object_to_goal_distance:\n",
      "    type: ObjectToGoalDistance\n",
      "  oracle_nav_action_SENSOR:\n",
      "    type: OracleNavigationActionSensor\n",
      "  pddl_domain_def: replica_cad\n",
      "  pick_reward:\n",
      "    constraint_violate_pen: 10.0\n",
      "    dist_reward: 20.0\n",
      "    drop_obj_should_end: False\n",
      "    drop_pen: 5.0\n",
      "    force_end_pen: 10.0\n",
      "    force_pen: 0.001\n",
      "    max_accum_force: 5000.0\n",
      "    max_force_pen: 1.0\n",
      "    pick_reward: 20.0\n",
      "    succ_reward: 10.0\n",
      "    type: RearrangePickReward\n",
      "    use_diff: True\n",
      "    wrong_pick_pen: 5.0\n",
      "    wrong_pick_should_end: False\n",
      "  pick_success:\n",
      "    ee_resting_success_threshold: 0.15\n",
      "    type: RearrangePickSuccess\n",
      "  place_reward:\n",
      "    constraint_violate_pen: 10.0\n",
      "    dist_reward: 20.0\n",
      "    drop_pen: 5.0\n",
      "    force_end_pen: 10.0\n",
      "    force_pen: 0.001\n",
      "    max_force_pen: 1.0\n",
      "    place_reward: 20.0\n",
      "    succ_reward: 10.0\n",
      "    type: PlaceReward\n",
      "    use_diff: True\n",
      "    wrong_drop_should_end: False\n",
      "  place_success:\n",
      "    ee_resting_success_threshold: 0.15\n",
      "    type: PlaceSuccess\n",
      "  pointgoal_sensor:\n",
      "    dimensionality: 2\n",
      "    goal_format: POLAR\n",
      "    type: PointGoalSensor\n",
      "  pointgoal_with_gps_compass_sensor:\n",
      "    dimensionality: 2\n",
      "    goal_format: POLAR\n",
      "    type: PointGoalWithGPSCompassSensor\n",
      "  possible_actions: ['stop', 'move_forward', 'turn_left', 'turn_right']\n",
      "  proximity_sensor:\n",
      "    max_detection_radius: 2.0\n",
      "    type: ProximitySensor\n",
      "  question_sensor:\n",
      "    type: QuestionSensor\n",
      "  rearrange_nav_to_obj_reward:\n",
      "    angle_dist_reward: 1.0\n",
      "    constraint_violate_pen: 10.0\n",
      "    dist_reward: 10.0\n",
      "    force_end_pen: 10.0\n",
      "    force_pen: 0.0\n",
      "    max_force_pen: 1.0\n",
      "    should_reward_turn: True\n",
      "    turn_reward_dist: 0.1\n",
      "    type: NavToObjReward\n",
      "  rearrange_nav_to_obj_success:\n",
      "    heuristic_stop: False\n",
      "    must_call_stop: True\n",
      "    must_look_at_targ: True\n",
      "    success_angle_dist: 0.15\n",
      "    type: NavToObjSuccess\n",
      "  rearrange_reach_reward:\n",
      "    diff_reward: True\n",
      "    scale: 1.0\n",
      "    sparse_reward: False\n",
      "    type: RearrangeReachReward\n",
      "  rearrange_reach_success:\n",
      "    succ_thresh: 0.2\n",
      "    type: RearrangeReachSuccess\n",
      "  relative_resting_pos_sensor:\n",
      "    type: RelativeRestingPositionSensor\n",
      "  render_target: True\n",
      "  resting_pos_sensor:\n",
      "    type: RestingPositionSensor\n",
      "  reward_measure: distance_to_goal_reward\n",
      "  robot_at_thresh: 2.0\n",
      "  robot_colls:\n",
      "    type: RobotCollisions\n",
      "  robot_force:\n",
      "    min_force: 20.0\n",
      "    type: RobotForce\n",
      "  rot_dist_to_goal:\n",
      "    type: RotDistToGoal\n",
      "  sensors: ['pointgoal_with_gps_compass_sensor']\n",
      "  settle_steps: 5\n",
      "  should_enforce_target_within_reach: False\n",
      "  should_save_to_cache: True\n",
      "  slack_reward: -0.01\n",
      "  soft_spl:\n",
      "    type: SoftSPL\n",
      "  spawn_region_scale: 0.2\n",
      "  spl:\n",
      "    type: SPL\n",
      "  success:\n",
      "    success_distance: 0.2\n",
      "    type: Success\n",
      "  success_measure: spl\n",
      "  success_reward: 2.5\n",
      "  success_state: 0.0\n",
      "  target_goal_gps_compass_sensor:\n",
      "    type: TargetGoalGpsCompassSensor\n",
      "  target_start_gps_compass_sensor:\n",
      "    type: TargetStartGpsCompassSensor\n",
      "  target_start_point_goal_sensor:\n",
      "    type: TargetOrGoalStartPointGoalSensor\n",
      "  target_start_sensor:\n",
      "    dimensionality: 3\n",
      "    goal_format: CARTESIAN\n",
      "    type: TargetStartSensor\n",
      "  task_spec: \n",
      "  task_spec_base_path: tasks/rearrange/pddl/\n",
      "  top_down_map:\n",
      "    draw_border: True\n",
      "    draw_goal_aabbs: True\n",
      "    draw_goal_positions: True\n",
      "    draw_shortest_path: True\n",
      "    draw_source: True\n",
      "    draw_view_points: True\n",
      "    fog_of_war:\n",
      "      draw: True\n",
      "      fov: 90\n",
      "      visibility_dist: 5.0\n",
      "    map_padding: 3\n",
      "    map_resolution: 1024\n",
      "    max_episode_steps: 1000\n",
      "    type: TopDownMap\n",
      "  type: Nav-v0\n",
      "  use_marker_t: True\n"
     ]
    }
   ],
   "source": [
    "from habitat.sims import make_sim\n",
    "env.current_episode.scene_dataset_config = online_env_config[\n",
    "        \"env_scene_dataset_config\"\n",
    "    ]\n",
    "env._config.defrost()\n",
    "env._config.simulator.scene_dataset = (\n",
    "                env.current_episode.scene_dataset_config\n",
    "            )\n",
    "env._config.freeze()\n",
    "print(env._config)\n",
    "env_sim = make_sim(\n",
    "           id_sim=env._config.simulator.type, config=env._config.simulator\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House has 0 levels, 0 regions and 0 objects\n",
      "House center:[0. 0. 0.] dims:[-inf -inf -inf]\n"
     ]
    }
   ],
   "source": [
    "def print_scene_recur(scene, limit_output=10):\n",
    "    print(f\"House has {len(scene.levels)} levels, {len(scene.regions)} regions and {len(scene.objects)} objects\")\n",
    "    print(f\"House center:{scene.aabb.center} dims:{scene.aabb.sizes}\")\n",
    "\n",
    "    count = 0\n",
    "    for level in scene.levels:\n",
    "        print(\n",
    "            f\"Level id:{level.id}, center:{level.aabb.center},\"\n",
    "            f\" dims:{level.aabb.sizes}\"\n",
    "        )\n",
    "        for region in level.regions:\n",
    "            print(\n",
    "                f\"Region id:{region.id}, category:{region.category.name()},\"\n",
    "                f\" center:{region.aabb.center}, dims:{region.aabb.sizes}\"\n",
    "            )\n",
    "            for obj in region.objects:\n",
    "                print(\n",
    "                    f\"Object id:{obj.id}, category:{obj.category.name()},\"\n",
    "                    f\" center:{obj.aabb.center}, dims:{obj.aabb.sizes}\"\n",
    "                )\n",
    "                count += 1\n",
    "                if count >= limit_output:\n",
    "                    return None\n",
    "\n",
    "# Print semantic annotation information (id, category, bounding box details)\n",
    "# about levels, regions and objects in a hierarchical fashion\n",
    "scene = env._sim.semantic_scene\n",
    "print_scene_recur(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "simulator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m goal_radius \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mepisodes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mgoals[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mradius\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m goal_radius \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     goal_radius \u001b[39m=\u001b[39m env_config\u001b[39m.\u001b[39msimulator\u001b[39m.\u001b[39mforward_step_size\n\u001b[1;32m      5\u001b[0m \u001b[39m# agent = PACTPointNavAgent(\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#     raw_action_space=env.habitat_env.action_space, agent_config=agent_config\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m      8\u001b[0m agent \u001b[39m=\u001b[39m ShortestPathFollowerAgent(env\u001b[39m.\u001b[39m_sim, goal_radius)\n",
      "File \u001b[0;32m/datadrive/anaconda3/envs/habitat/lib/python3.8/site-packages/yacs/config.py:141\u001b[0m, in \u001b[0;36mCfgNode.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m    140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: simulator"
     ]
    }
   ],
   "source": [
    "# simple agent from native habitat\n",
    "goal_radius = env.episodes[0].goals[0].radius\n",
    "if goal_radius is None:\n",
    "    goal_radius = env_config.habitat.simulator.forward_step_size\n",
    "# agent = PACTPointNavAgent(\n",
    "#     raw_action_space=env.habitat_env.action_space, agent_config=agent_config\n",
    "# )\n",
    "agent = ShortestPathFollowerAgent(env._sim, goal_radius)\n",
    "print(\"Environment creation successful\")\n",
    "\n",
    "for episode in range(online_env_config[\"num_episodes\"]):\n",
    "    env.current_episode.scene_dataset_config = online_env_config[\n",
    "        \"env_scene_dataset_config\"\n",
    "    ]\n",
    "\n",
    "    observations = env.reset()\n",
    "    env.current_episode.scene_dataset_config = online_env_config[\n",
    "        \"env_scene_dataset_config\"\n",
    "    ]\n",
    "    with habitat.config.read_write(env_config):\n",
    "        env_config.habitat.simulator.scene_dataset = online_env_config[\n",
    "            \"env_scene_dataset_config\"\n",
    "        ]\n",
    "    dataset_collector.episode_start(\n",
    "        env.current_episode.__getstate__()\n",
    "    )\n",
    "\n",
    "    # RLEnv.reset() only returns observations: https://aihabitat.org/docs/habitat-lab/habitat.core.env.RLEnv.html\n",
    "    step = 0\n",
    "    while not env.episode_over:\n",
    "        # action = agent.act(observations)\n",
    "        action = agent.act(env.current_episode.goals[0].position)\n",
    "        if action is None:\n",
    "            break\n",
    "\n",
    "        next_observations = env.step(action)\n",
    "        print(next_observations.keys())\n",
    "        observations = next_observations\n",
    "\n",
    "        step += 1\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House has 0 levels, 0 regions and 0 objects\n",
      "House center:[0. 0. 0.] dims:[-inf -inf -inf]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentConfiguration(height=1.5, radius=0.1, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7f2a63a95680>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder')\n"
     ]
    }
   ],
   "source": [
    "print(agent_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action move_forward\n",
      "{'semantic': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32), 'collided': False}\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "action move_forward\n",
      "{'semantic': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32), 'collided': False}\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "action move_forward\n",
      "{'semantic': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32), 'collided': False}\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "action move_forward\n",
      "{'semantic': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32), 'collided': False}\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "action move_forward\n",
      "{'semantic': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32), 'collided': False}\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('habitat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbae9d0b84959119de7b4f7e414ec47420c94687cd5fb0eaaf8941084ecf28af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
